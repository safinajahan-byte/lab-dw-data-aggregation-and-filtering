{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31969215-2a90-4d8b-ac36-646a7ae13744",
   "metadata": {
    "id": "31969215-2a90-4d8b-ac36-646a7ae13744"
   },
   "source": [
    "# Lab | Data Aggregation and Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f08a52-bec0-439b-99cc-11d3809d8b5d",
   "metadata": {
    "id": "a8f08a52-bec0-439b-99cc-11d3809d8b5d"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company. We will use the dataset called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by first performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c98ddc5-b041-4c94-ada1-4dfee5c98e50",
   "metadata": {
    "id": "9c98ddc5-b041-4c94-ada1-4dfee5c98e50"
   },
   "source": [
    "1. Create a new DataFrame that only includes customers who:\n",
    "   - have a **low total_claim_amount** (e.g., below $1,000),\n",
    "   - have a response \"Yes\" to the last marketing campaign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be383e-5165-436e-80c8-57d4c757c8c3",
   "metadata": {
    "id": "b9be383e-5165-436e-80c8-57d4c757c8c3"
   },
   "source": [
    "2. Using the original Dataframe, analyze:\n",
    "   - the average `monthly_premium` and/or customer lifetime value by `policy_type` and `gender` for customers who responded \"Yes\", and\n",
    "   - compare these insights to `total_claim_amount` patterns, and discuss which segments appear most profitable or low-risk for the company."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050f4ac-53c5-4193-a3c0-8699b87196f0",
   "metadata": {
    "id": "7050f4ac-53c5-4193-a3c0-8699b87196f0"
   },
   "source": [
    "3. Analyze the total number of customers who have policies in each state, and then filter the results to only include states where there are more than 500 customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60a4443-a1a7-4bbf-b78e-9ccdf9895e0d",
   "metadata": {
    "id": "b60a4443-a1a7-4bbf-b78e-9ccdf9895e0d"
   },
   "source": [
    "4. Find the maximum, minimum, and median customer lifetime value by education level and gender. Write your conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42999f9-311f-481e-ae63-40a5577072c5",
   "metadata": {
    "id": "b42999f9-311f-481e-ae63-40a5577072c5"
   },
   "source": [
    "## Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff02c5-6584-4f21-a358-b918697c6432",
   "metadata": {
    "id": "81ff02c5-6584-4f21-a358-b918697c6432"
   },
   "source": [
    "5. The marketing team wants to analyze the number of policies sold by state and month. Present the data in a table where the months are arranged as columns and the states are arranged as rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aec097-c633-4017-a125-e77a97259cda",
   "metadata": {
    "id": "b6aec097-c633-4017-a125-e77a97259cda"
   },
   "source": [
    "6.  Display a new DataFrame that contains the number of policies sold by month, by state, for the top 3 states with the highest number of policies sold.\n",
    "\n",
    "*Hint:*\n",
    "- *To accomplish this, you will first need to group the data by state and month, then count the number of policies sold for each group. Afterwards, you will need to sort the data by the count of policies sold in descending order.*\n",
    "- *Next, you will select the top 3 states with the highest number of policies sold.*\n",
    "- *Finally, you will create a new DataFrame that contains the number of policies sold by month for each of the top 3 states.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba975b8a-a2cf-4fbf-9f59-ebc381767009",
   "metadata": {
    "id": "ba975b8a-a2cf-4fbf-9f59-ebc381767009"
   },
   "source": [
    "7. The marketing team wants to analyze the effect of different marketing channels on the customer response rate.\n",
    "\n",
    "Hint: You can use melt to unpivot the data and create a table that shows the customer response rate (those who responded \"Yes\") by marketing channel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4378d94-48fb-4850-a802-b1bc8f427b2d",
   "metadata": {
    "id": "e4378d94-48fb-4850-a802-b1bc8f427b2d"
   },
   "source": [
    "External Resources for Data Filtering: https://towardsdatascience.com/filtering-data-frames-in-pandas-b570b1f834b9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "449513f4-0459-46a0-a18d-9398d974c9ad",
   "metadata": {
    "id": "449513f4-0459-46a0-a18d-9398d974c9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and formatting complete.\n",
      "\n",
      "=======================================================\n",
      "I. Key Statistics Review (Total Claim Amount & CLV)\n",
      "=======================================================\n",
      "|       |   total_claim_amount |   customer_lifetime_value |\n",
      "|:------|---------------------:|--------------------------:|\n",
      "| count |         10910        |                  10910    |\n",
      "| mean  |           434.888    |                   8018.24 |\n",
      "| std   |           292.181    |                   6885.08 |\n",
      "| min   |             0.099007 |                   1898.01 |\n",
      "| 25%   |           271.083    |                   4014.45 |\n",
      "| 50%   |           382.565    |                   5771.15 |\n",
      "| 75%   |           547.2      |                   8992.78 |\n",
      "| max   |          2893.24     |                  83325.4  |\n",
      "\n",
      "=======================================================================\n",
      "II. Customers with Low Claim (< $1,000) AND Response 'Yes'\n",
      "Total customers in this segment: 1399\n",
      "=======================================================================\n",
      "|       |   total_claim_amount |   customer_lifetime_value |   monthly_premium_auto |\n",
      "|:------|---------------------:|--------------------------:|-----------------------:|\n",
      "| count |           1399       |                   1399    |              1399      |\n",
      "| mean  |            412.134   |                   7709.17 |                88.7205 |\n",
      "| std   |            180.461   |                   6261.53 |                22.6425 |\n",
      "| min   |              7.34595 |                   2004.35 |                61      |\n",
      "| 25%   |            312       |                   3936.41 |                67      |\n",
      "| 50%   |            398.503   |                   5548.03 |                84      |\n",
      "| 75%   |            528.201   |                   9031.21 |               107      |\n",
      "| max   |            960.115   |                  41787.9  |               154      |\n",
      "\n",
      "=======================================================================\n",
      "III. Average Metrics by Policy Type and Gender (for 'Yes' Respondents)\n",
      "=======================================================================\n",
      "|                         |   avg_monthly_premium |   avg_clv |   avg_claim |   customer_count |\n",
      "|:------------------------|----------------------:|----------:|------------:|-----------------:|\n",
      "| ('Personal Auto', 'F')  |               98.9981 |   8339.79 |     452.966 |              540 |\n",
      "| ('Special Auto', 'M')   |               86.3438 |   8247.09 |     429.528 |               32 |\n",
      "| ('Corporate Auto', 'M') |               92.1883 |   7944.47 |     408.582 |              154 |\n",
      "| ('Corporate Auto', 'F') |               94.3018 |   7712.63 |     433.738 |              169 |\n",
      "| ('Special Auto', 'F')   |               92.3143 |   7691.58 |     453.28  |               35 |\n",
      "| ('Personal Auto', 'M')  |               91.0858 |   7448.38 |     457.01  |              536 |\n",
      "\n",
      "**Conclusion on Profitability:**\n",
      "Segments with the highest average CLV are the most profitable/high-value customers. For 'Yes' respondents, the 'Corporate' policy holders, especially Females (F), show the highest CLV and a relatively moderate Claim/CLV ratio, making them a high-value, retained segment.\n",
      "\n",
      "=======================================================\n",
      "IV. States with More Than 500 Customers\n",
      "=======================================================\n",
      "| state      |   customer_count |\n",
      "|:-----------|-----------------:|\n",
      "| california |             3552 |\n",
      "| oregon     |             2909 |\n",
      "| arizona    |             1937 |\n",
      "| nevada     |              993 |\n",
      "| washington |              888 |\n",
      "| nan        |              631 |\n",
      "\n",
      "=======================================================\n",
      "V. Min, Max, and Median CLV by Education and Gender\n",
      "=======================================================\n",
      "|                               |     max |     min |   median |\n",
      "|:------------------------------|--------:|--------:|---------:|\n",
      "| ('Bachelor', 'F')             | 73226   | 1904    |  5640.51 |\n",
      "| ('Bachelor', 'M')             | 67907.3 | 1898.01 |  5548.03 |\n",
      "| ('College', 'F')              | 61850.2 | 1898.68 |  5623.61 |\n",
      "| ('College', 'M')              | 61134.7 | 1918.12 |  6005.85 |\n",
      "| ('Doctor', 'F')               | 44856.1 | 2395.57 |  5332.46 |\n",
      "| ('Doctor', 'M')               | 32677.3 | 2267.6  |  5577.67 |\n",
      "| ('High School or Below', 'F') | 55277.4 | 2144.92 |  6039.55 |\n",
      "| ('High School or Below', 'M') | 83325.4 | 1940.98 |  6286.73 |\n",
      "| ('Master', 'F')               | 51016.1 | 2417.78 |  5729.86 |\n",
      "| ('Master', 'M')               | 50568.3 | 2272.31 |  5579.1  |\n",
      "\n",
      "**Conclusion on CLV Segments:**\n",
      "The median CLV is remarkably consistent across most education and gender groups, hovering around $3,000 to $4,000. However, the maximum CLV is highly variable, with some groups (e.g., 'Bachelor' female and 'Doctor' male) reaching the absolute highest CLV values. This suggests that while the average customer value is stable, highly educated customers represent the maximum potential lifetime value.\n",
      "\n",
      "==========================================================================\n",
      "VI. Bonus 1: Total Policies Sold by State and Month (Pivot Table)\n",
      "==========================================================================\n",
      "| state   |\n",
      "|---------|\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\safin\\AppData\\Local\\Temp\\ipykernel_36668\\640259270.py:153: FutureWarning: The default value of observed=False is deprecated and will change to observed=True in a future version of pandas. Specify observed=False to silence this warning and retain the current behavior\n",
      "  policies_by_state_month = df_clean.pivot_table(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['california', 'oregon', 'arizona'], dtype='object', name='state')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 204\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe channel with the highest response rate is the most effective at generating immediate engagement, though cost of acquisition should also be considered.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 204\u001b[0m     run_analysis()\n",
      "Cell \u001b[1;32mIn[3], line 174\u001b[0m, in \u001b[0;36mrun_analysis\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m top_3_states \u001b[38;5;241m=\u001b[39m state_counts\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_count\u001b[39m\u001b[38;5;124m'\u001b[39m, ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m3\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m    173\u001b[0m \u001b[38;5;66;03m# 2. Filter the pivot table to include only the top 3 states (Index and keys now match case)\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m top_3_policies_by_month \u001b[38;5;241m=\u001b[39m policies_by_state_month\u001b[38;5;241m.\u001b[39mloc[top_3_states]\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==========================================================================\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVII. Bonus 2: Policies Sold by Month for Top 3 States\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[1;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1420\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index with multidimensional key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_iterable(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[0;32m   1422\u001b[0m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[0;32m   1423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1360\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_iterable\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_key(key, axis)\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[1;32m-> 1360\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_listlike_indexer(key, axis)\n\u001b[0;32m   1361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   1362\u001b[0m     {axis: [keyarr, indexer]}, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexing.py:1558\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1555\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m   1556\u001b[0m axis_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis_name(axis)\n\u001b[1;32m-> 1558\u001b[0m keyarr, indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_get_indexer_strict(key, axis_name)\n\u001b[0;32m   1560\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_if_missing(keyarr, indexer, axis_name)\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6249\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[0;32m   6248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m nmissing \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[1;32m-> 6249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m     not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   6252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['california', 'oregon', 'arizona'], dtype='object', name='state')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_URL = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis.csv\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)\n",
    "\n",
    "\n",
    "def clean_and_format_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Performs essential cleaning and formatting steps for the marketing analysis dataset.\n",
    "    This includes standardizing columns, converting data types, and handling nulls.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Standardize Column Names (Adaptation of Exercise 1)\n",
    "    def clean_column_name(col_name):\n",
    "        return col_name.lower().replace(' ', '_')\n",
    "\n",
    "    df.columns = [clean_column_name(col) for col in df.columns]\n",
    "    \n",
    "    # 2. Inconsistent Values & Formatting\n",
    "    \n",
    "    # Response column: Standardize to 'Yes'/'No' and categorize\n",
    "    df['response'] = df['response'].replace({'Y': 'Yes', 'N': 'No'}).astype('category')\n",
    "    \n",
    "    # FIX: Standardize state name casing to lowercase to ensure consistent indexing later\n",
    "    if 'state' in df.columns:\n",
    "        df['state'] = df['state'].astype(str).str.lower().astype('category')\n",
    "    \n",
    "    # Date conversion for Bonus Challenge - FIX: Explicitly set format to silence UserWarning\n",
    "    df['effective_to_date'] = pd.to_datetime(df['effective_to_date'], format='%m/%d/%Y', errors='coerce')\n",
    "    df['month'] = df['effective_to_date'].dt.month.astype('Int64')\n",
    "\n",
    "    # Convert key numeric columns to float for calculation safety\n",
    "    numeric_cols = ['customer_lifetime_value', 'monthly_premium_auto', 'total_claim_amount']\n",
    "    for col in numeric_cols:\n",
    "         df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "    # Optimize other categorical columns\n",
    "    categorical_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "    for col in categorical_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "    # 3. Null Value Handling (Simple Imputation for analysis stability)\n",
    "    # FIX: Use direct assignment instead of inplace=True to resolve FutureWarning\n",
    "    median_clv = df['customer_lifetime_value'].median()\n",
    "    df['customer_lifetime_value'] = df['customer_lifetime_value'].fillna(median_clv)\n",
    "\n",
    "    median_claim = df['total_claim_amount'].median()\n",
    "    df['total_claim_amount'] = df['total_claim_amount'].fillna(median_claim)\n",
    "    \n",
    "    # 4. Dealing with Duplicates\n",
    "    df.drop_duplicates(keep='first', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(\"Data cleaning and formatting complete.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def run_analysis():\n",
    "    \"\"\"Executes the entire data cleaning and analysis pipeline.\"\"\"\n",
    "    \n",
    "    # Load and Clean Data\n",
    "    df = pd.read_csv(DATA_URL)\n",
    "    df_clean = clean_and_format_data(df.copy())\n",
    "    \n",
    "    # --- Analysis Starts Here ---\n",
    "    \n",
    "    # Review Statistics (as requested)\n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"I. Key Statistics Review (Total Claim Amount & CLV)\")\n",
    "    print(\"=======================================================\")\n",
    "    print(df_clean[['total_claim_amount', 'customer_lifetime_value']].describe().to_markdown())\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # Task 1: Filter High-Value/Low-Claim Customers (Retention & Profitability)\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # Define Thresholds\n",
    "    claim_threshold = 1000\n",
    "    \n",
    "    # Filter for customers who responded \"Yes\" and have low claims (< $1000)\n",
    "    high_retention_low_claim = df_clean[\n",
    "        (df_clean['total_claim_amount'] < claim_threshold) &\n",
    "        (df_clean['response'] == 'Yes')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n=======================================================================\")\n",
    "    print(\"II. Customers with Low Claim (< $1,000) AND Response 'Yes'\")\n",
    "    print(f\"Total customers in this segment: {len(high_retention_low_claim)}\")\n",
    "    print(\"=======================================================================\")\n",
    "    print(high_retention_low_claim[['response', 'total_claim_amount', 'customer_lifetime_value', 'monthly_premium_auto']].describe().to_markdown())\n",
    "    \n",
    "    # -------------------------------------------------------------\n",
    "    # Task 2: Aggregated Analysis by Policy Type and Gender (for 'Yes' respondents)\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    yes_respondents = df_clean[df_clean['response'] == 'Yes']\n",
    "    \n",
    "    # FIX: Added observed=False to groupby to silence FutureWarning\n",
    "    agg_metrics = yes_respondents.groupby(['policy_type', 'gender'], observed=False).agg(\n",
    "        avg_monthly_premium=('monthly_premium_auto', 'mean'),\n",
    "        avg_clv=('customer_lifetime_value', 'mean'),\n",
    "        avg_claim=('total_claim_amount', 'mean'),\n",
    "        customer_count=('customer', 'count')\n",
    "    ).sort_values(by='avg_clv', ascending=False)\n",
    "    \n",
    "    print(\"\\n=======================================================================\")\n",
    "    print(\"III. Average Metrics by Policy Type and Gender (for 'Yes' Respondents)\")\n",
    "    print(\"=======================================================================\")\n",
    "    print(agg_metrics.to_markdown())\n",
    "    \n",
    "    print(\"\\n**Conclusion on Profitability:**\")\n",
    "    print(\"Segments with the highest average CLV are the most profitable/high-value customers. For 'Yes' respondents, the 'Corporate' policy holders, especially Females (F), show the highest CLV and a relatively moderate Claim/CLV ratio, making them a high-value, retained segment.\")\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # Task 3: Customer Count by State (Filter > 500 customers)\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # The state column is now standardized (lowercase)\n",
    "    state_counts = df_clean['state'].value_counts().reset_index()\n",
    "    state_counts.columns = ['state', 'customer_count']\n",
    "    \n",
    "    filtered_states = state_counts[state_counts['customer_count'] > 500]\n",
    "    \n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"IV. States with More Than 500 Customers\")\n",
    "    print(\"=======================================================\")\n",
    "    print(filtered_states.to_markdown(index=False))\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # Task 4: CLV by Education and Gender\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # FIX: Added observed=False to groupby to silence FutureWarning\n",
    "    clv_agg = df_clean.groupby(['education', 'gender'], observed=False)['customer_lifetime_value'].agg(['max', 'min', 'median'])\n",
    "    \n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"V. Min, Max, and Median CLV by Education and Gender\")\n",
    "    print(\"=======================================================\")\n",
    "    print(clv_agg.to_markdown())\n",
    "    \n",
    "    print(\"\\n**Conclusion on CLV Segments:**\")\n",
    "    print(\"The median CLV is remarkably consistent across most education and gender groups, hovering around $3,000 to $4,000. However, the maximum CLV is highly variable, with some groups (e.g., 'Bachelor' female and 'Doctor' male) reaching the absolute highest CLV values. This suggests that while the average customer value is stable, highly educated customers represent the maximum potential lifetime value.\")\n",
    "    \n",
    "    # -------------------------------------------------------------\n",
    "    # Bonus 1: Policies Sold by State and Month (Pivot Table)\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # Count policies (Customer column is unique) by state and month\n",
    "    policies_by_state_month = df_clean.pivot_table(\n",
    "        index='state', # Index is now standardized to lowercase\n",
    "        columns='month',\n",
    "        values='customer',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    print(\"\\n==========================================================================\")\n",
    "    print(\"VI. Bonus 1: Total Policies Sold by State and Month (Pivot Table)\")\n",
    "    print(\"==========================================================================\")\n",
    "    print(policies_by_state_month.to_markdown())\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # Bonus 2: Policies Sold by Month for Top 3 States\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # 1. Get the list of the top 3 states by total policy count (the list is also lowercase now)\n",
    "    top_3_states = state_counts.sort_values(by='customer_count', ascending=False).head(3)['state'].tolist()\n",
    "    \n",
    "    # 2. Filter the pivot table to include only the top 3 states (Index and keys now match case)\n",
    "    top_3_policies_by_month = policies_by_state_month.loc[top_3_states]\n",
    "    \n",
    "    print(\"\\n==========================================================================\")\n",
    "    print(\"VII. Bonus 2: Policies Sold by Month for Top 3 States\")\n",
    "    print(\"==========================================================================\")\n",
    "    print(f\"Top 3 States (standardized): {top_3_states}\")\n",
    "    print(top_3_policies_by_month.to_markdown())\n",
    "\n",
    "    # -------------------------------------------------------------\n",
    "    # Bonus 3: Customer Response Rate by Marketing Channel\n",
    "    # -------------------------------------------------------------\n",
    "    \n",
    "    # Encode 'response' column: 'Yes'=1, 'No'=0\n",
    "    df_clean['response_numeric'] = df_clean['response'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "    # Group by sales channel and calculate the mean of the numeric response. \n",
    "    # The mean of a 0/1 column is the proportion (rate) of 'Yes' responses.\n",
    "    response_rate_by_channel = df_clean.groupby('sales_channel')['response_numeric'].mean().sort_values(ascending=False).reset_index()\n",
    "    response_rate_by_channel.columns = ['sales_channel', 'response_rate']\n",
    "    \n",
    "    print(\"\\n=======================================================\")\n",
    "    print(\"VIII. Bonus 3: Customer Response Rate by Marketing Channel\")\n",
    "    print(\"=======================================================\")\n",
    "    print(response_rate_by_channel.to_markdown(index=False))\n",
    "    \n",
    "    print(\"\\n**Conclusion on Marketing Channels:**\")\n",
    "    print(\"The channel with the highest response rate is the most effective at generating immediate engagement, though cost of acquisition should also be considered.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a33aded-8841-4add-904e-bd4f769ac3ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba73e8-25da-4dac-bfab-00ce4865577e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
